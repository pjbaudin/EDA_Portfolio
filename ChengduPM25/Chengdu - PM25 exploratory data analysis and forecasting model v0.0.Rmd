---
title: "PM2.5 level in Chengdu - Exploratory Data Analysis"
author: "Pierre Baudin"
date: "March 17, 2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
```

Note: the complete code will be available on my github repository to support reproducible research. ([Full code repo](https://github.com/pjbaudin))

## Synopsis

Cities accross the world are facing air pollution problems that are generated by human activity. Air pollution has been recognized to be a factor in the increase of respiratory diseases in urban population.

Increasingly, cities are developing programs to reduce the air pollution and decrease the health risk on the population.

In this explanatory data analysis, we will look at the city of Chengdu and its PM2.5 pollution level. PM2.5 stands for Particule Matter and describes fine inhalable particles, with diameters that are generally 2.5 micrometers and smaller.

The data for this project is downloaded from the American embassy in Chengdu. (see: http://www.stateair.net/web/post/1/2.html). We are grateful for the U.S. Department of State to open access to the data. The website also warns that these data are not fully verified or validated.

The objective of this project is to explore the dataset, identify trends and finally propose a forecasting model.

## Data preparation

### Collection and combining

The historical data from the American embassy in Chengdu are available for download. For each year from 2013 to 2017, there is one comma separated value file (.csv). All of the files have been downloaded.

A preliminary check (not shown here) has revealed that the data formating in the csv file has been changed between 2014 and 2015. For this reason, the import and binding is done in two stage.

```{r import combine, message=FALSE, warning=FALSE}
# Import libraries
library(dplyr) # data manipulation and pipe operator
library(lubridate) # easy processing of time-based data

# Set the working directory which contains the yearly historical data
setwd("C:/Users/pierr/Documents/GitHub/EDA_Portfolio/ChengduPM25")

# Create a vector with the files names
FileNames <- list.files(pattern = ".csv")

# Initiate main dataframe for all years combined
maindf <- data.frame()

# Loop to import and bind the year 2013 and 2014
for (i in 1:2) {
  df <- read.csv(FileNames[i], skip = 2)
  maindf <- bind_rows(maindf, df)
}

# Convert date into POSIXct POSIXt format
maindf$Date..LST. <- ymd_hm(maindf$Date..LST.)

# Loop over data from 2015 to 2017
for (i in 3:5) {
  df <- read.csv(FileNames[i], skip = 3)
  df$Date..LST. <- mdy_hm(df$Date..LST.) # convertion to standard date format
  maindf <- bind_rows(maindf, df)
}

# Convert features format
maindf$Value <- as.numeric(maindf$Value)
ind <- c("Year", "Month", "Day", "Hour")
maindf[, ind] <- lapply(maindf[, ind], as.factor)

# Convert month into coresponding string factors
monthdf <- data.frame(Nbr = as.factor(c(1:12)),
                      Month_str = factor(c("Jan", "Feb", "Mar", "Apr",
                                               "May", "Jun", "Jul", "Aug",
                                               "Sep", "Oct", "Nov", "Dec"),
                                            levels = c("Jan", "Feb", "Mar", "Apr",
                                               "May", "Jun", "Jul", "Aug",
                                               "Sep", "Oct", "Nov", "Dec")))
maindf <- maindf %>%
  left_join(monthdf, by = c("Month" = "Nbr")) %>%
  mutate(Month = Month_str, Month_str = NULL)


# Display structure and first rows of the main dataframe
print("Structure of the dataset")
str(maindf)
```

/newpage

```{r}
print("First 6 rows of the dataset")
head(maindf)
```

### Interpretation of the dataset

```{r}
summary(maindf)
```

We can observe that the dataset is only for Chengdu as a site and the PM2.5 as a parameter. Observations are logged on an hourly basis. Interestingly we note that the number of observations for the year 2017 is incomplete. For the year 2013 to 2016, the number of observations correspond exactly to the number of days in the year multiplied by 24 hours.

Regarding the value measured, we see that the minimum is -999.00 which has no meaning. There are also 2036 observations with QC.Name as "Missing".

```{r}
table(maindf[maindf$Value == -999, "QC.Name"])
```

We can now confirm that the value recorded for missing QC is -999.

We choose to replace these missing value using a linear interpolation method. From then on, we will ignore the QC.Name variable.

```{r}
# load library for time series and approximation function
library(zoo)

# Data processing to extrpolate NA values
maindf$Value <- ifelse(maindf$Value < 0, NA, maindf$Value)
maindf_pro <- maindf
maindf_pro$Value <- na.approx(maindf_pro$Value)
maindf_pro$QC.Name <- NULL
```

This is now the summary of our final dataset ready for exploratory data analysis.
```{r}
summary(maindf_pro)
```

For the period of 2013 to mid-2017, the PM2.5 levels in Chengdu have a mean of 79.84 ug/m3, a median of 65.00 ug/m3. Peaks are observed at a maximum of 688.00 ug/m3 and a minimum of 0.00 ug/m3. We note that these value are extreme and need to be taken with caution. Elements such a measuring equipment, location and calibration could influence such readings.

\newpage

## Visualization and Trends

### By Year

In this section, we will explore the PM2.5 level on a yearly basis and answer the following question: overall, have the PM2.5 pollution levels decrease over time in Chengdu?

Note: the year 2017 being incomplete, it will be ignored in this part of the analysis to avoid misinterpretation.

```{r}
# load library for data vizualisation
library(ggplot2)

# Yearly pollution level boxplot
maindf_pro %>%
  filter(Year != 2017) %>%
  ggplot(aes(x = Year, y = Value, group = Year)) +
  geom_boxplot() +
  labs(title = "PM2.5 level from 2013 to 2016 in Chengdu",
         x = "", y = "PM2.5 value (ug/m3)") +
  theme_light()
```

```{r}
maindf_pro %>%
  filter(Year != 2017) %>%
  group_by(Year) %>%
  summarize(YearMean = round(mean(Value), digits = 2),
            YearMedian = median(Value),
            YearStd = round(sd(Value), digits = 2),
            YearMax = max(Value),
            YearMin = min(Value))
```

**Interpretation:**

We can see that over the year, the average level of PM2.5 in the air has decreased overall. It seems to stabilize in 2016. However, the standard deviation indicates that there are less extreme readings in 2016 which the maximum value recorded in that year confirms.

\newpage

### Seasonality

In this section, we will look at the seasonality of the PM2.5 level accross year, months and weeks. The aim is to identify patterns and trends that will be useful in the construction of a model.

#### Heatmap

The heatmap shows for each week day, each month and each year, the maximum PM2.5 level measured during that day.

The year 2017 although incomplete is included in this analysis to make use of the monthly data.

```{r}
maindf_pro %>%
  mutate(Week = ceiling(day(Date..LST.) / 7),
         Day_str = factor(weekdays(Date..LST., abbreviate = TRUE),
                          levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))) %>%
  group_by(Year, Month, Week, Day_str) %>%
  summarize(DayMax = max(Value)) %>%
  ggplot(aes(Week, Day_str, fill = DayMax)) + 
  geom_tile(colour = "white") + 
  facet_grid(Year ~ Month) + 
  scale_fill_gradient2(high = "black", mid ="red", low = "blue") +
  labs(x="Week of Month",
       y="",
       title = "Time-Series Calendar Heatmap", 
       subtitle="Chengdu - PM2.5 level", 
       fill = "PM2.5 level")
```

**Interpretation:**

The months of from January to April and October to December record higher pollution level compare to the period from June to September.
January and December appear to be the worst month of the year each year.

We can also observe that over the year it seems that the highest level of PM2.5 recorded have decreased i.e. extreme values are less extreme.

In the following paragraph, we will investigate these findings.

\newpage

### Trend and peaks

In this section, we will look at the monthly data to investigate trends over the year.

The table containing the monthly summary is available in the annexes section.


```{r}
# Initiate color palette
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# Ploting
maindf_pro %>%
  ggplot(aes(x = Month, y = Value, group = interaction(Year, Month), fill = Year)) +
  geom_boxplot(alpha = 0.6,
               outlier.fill = "red", outlier.alpha = 0.6) +
  scale_fill_manual(values = cbPalette) +
  scale_y_continuous(breaks = seq(0, 700, 50)) +
  labs(title = "Monthly PM2.5 distribution grouped by year",
       x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.justification = c(1, 1), legend.position = c(1, 1))
```

**Interpretation:**

We can now confirm the observations from the heatmap. The period from October to March shows a rise in pollution level with a peak in January, followed by a decline afterwards.
The months with the lowest pollution level and lowest extreme values are July and August.

These trends are visible accross years. We now look at the yearly trend and fit a regression line to highlight the trends.
The folowing graph describes the maximum values recorded each day and identify the trends for each year and over the years.

```{r}
maindf_pro %>%
  mutate(DayofYear = as.numeric(format(Date..LST., "%j"))) %>%
  group_by(Year, Month, Day) %>%
  summarize(DayMax = max(Value),
            DayofYear = DayofYear[1]) %>%
  ggplot(aes(DayofYear, DayMax, color = Year)) +
  geom_jitter(alpha = 0.4) +
  stat_smooth(method = "loess", color = "black", alpha = 0.6) +
  facet_grid(. ~ Year) +
  scale_color_manual(values = cbPalette) +
  scale_y_continuous(breaks = seq(0, 800, 100)) +
  labs(title = "Peak PM2.5 level in Chengdu over the years",
       subtitle = "With Local Polynomial Regression",
       x = "Day of the Year",
       y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.position = "none")
```

The regression model helps to confirm the visual interpretation of the data. We can now confirm that hyperbolic shape of the PM2.5 level for each years.

```{r}
library(gridExtra)

p1 <- maindf_pro %>%
  filter(Year != 2017) %>%
  group_by(Year, Month, Day) %>%
  summarize(DayMax = max(Value),
            Date = Date..LST.[1]) %>%
  ggplot(aes(Date, DayMax, color = Year)) +
  geom_jitter(alpha = 0.4) +
  scale_y_continuous(breaks = seq(0, 800, 100)) +
  scale_color_manual(values = cbPalette) +
  stat_smooth(method = "lm", color = "black", alpha = 0.6) +
  labs(title = "Peak PM2.5 level in Chengdu over the years",
       subtitle =  "Maximum level - With linear regression", x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.position = "none")


p2 <- maindf_pro %>%
  filter(Year != 2017) %>%
  group_by(Year, Month, Day) %>%
  summarize(DayMed = median(Value),
            Date = Date..LST.[1]) %>%
  ggplot(aes(Date, DayMed, color = Year)) +
  geom_jitter(alpha = 0.4) +
  scale_y_continuous(breaks = seq(0, 800, 100)) +
  scale_color_manual(values = cbPalette) +
  scale_y_continuous(breaks = seq(0, 400, 50)) +
  stat_smooth(method = "lm", color = "black", alpha = 0.6) +
  labs(subtitle = "Median level - With linear regression", x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.position = "none")

grid.arrange(p1, p2)

```

For this part, the year 2017 has been ignored to avoid skewed the model. 

The linear regression line over the entire dataset from 2013 to 2016 presents a negtive slope for both the maximum values and median values. This indicates a reduction over time of median and extreme PM2.5 pollution level in Chengdu.

\newpage

### Chinese New Year and PM2.5 level

In China, an interesting period to study is the Chinese New Year. This period of the year is describe as a modern migration phenomenon as Chinese people uses transport to enjoy this time in their hometown or travel to visit places. This is also the time where fireworks are used to celebrate the New Year.
The following graph identify the Chinese New Year day and the corresponding maximum pollution level recorded.

```{r}
CNY_date_Feb <- data.frame(Year = c(2013, 2015, 2016),
                       CNY_date = c(10, 19, 8))

p1 <- maindf_pro %>%
  filter(Month == "Feb", Year == c(2013, 2015, 2016)) %>%
  group_by(Year, Day) %>%
  summarize(DayMax = max(Value)) %>%
  ggplot(aes(x = Day, y = DayMax, group = Year, fill = Year)) +
  geom_col(alpha = 0.6) +
  facet_grid(Year ~ .) +
  geom_vline(aes(xintercept = CNY_date), CNY_date_Feb,
             lwd = 1.5, lty = 1, color = "red") +
  scale_fill_manual(values = cbPalette) +
  scale_y_continuous(breaks = seq(0, 600, 200)) +
  labs(title = "Chinese New Year - PM2.5 level",
       subtitle = "Year with CNY in February",
       x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.position = "none")

CNY_date_Jan <- data.frame(Year = c(2014, 2017),
                       CNY_date = c(31, 28))

p2 <- maindf_pro %>%
  filter(Month == "Jan", Year == c(2014, 2017)) %>%
  group_by(Year, Day) %>%
  summarize(DayMax = max(Value)) %>%
  ggplot(aes(x = Day, y = DayMax, group = Year, fill = Year)) +
  geom_col(alpha = 0.6) +
  facet_grid(Year ~ .) +
  geom_vline(aes(xintercept = CNY_date), CNY_date_Jan,
             lwd = 1.5, lty = 1, color = "red") +
  scale_fill_manual(values = cbPalette) +
  labs(subtitle = "Year with CNY in January",
       x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.position = "none")

grid.arrange(p1, p2)

```

**Interpretation**

The graph seems to indicate that after 2014, the PM2.5 pollution level during Chinese New Year are comparable to average level in the city of Chengdu. This might be the result of a policy change by the Chengdu government.

\newpage

## Forecasting model

In this section, we will use the historical data from 2013 to 2016 and train a model to predict the median pollution level in the first six months of 2017.
The data from 2017 will be kept as a test set to evaluate the model accuracy and the model will be trained on monthly median pollution level

Two modeling techniques are tested and compared for the forecasting of the data:
  - ARIMA model: an autoregressive integrated moving average (ARIMA) model is a generalization of an autoregressive moving average (ARMA) model
  - Exponential smoothing model: Exponential Smoothing is a technique to make forecasts by using a weighted mean of past values, wherein more recent values are given higher weights. 

These two methods are commonly used to model time series with a seasonality component.

```{r}

library(forecast)

# Create time serie for median per month
data <- maindf_pro %>%
  group_by(Year, Month) %>%
  summarize(MonthMed = median(Value)) %>%
  ungroup() %>%
  select(MonthMed)

data_ts <- ts(data$MonthMed, frequency = 12, start = c(2013, 1))

# Sample time serie for training and testing
smpl1 <- window(data_ts, end = c(2016, 12))
smpl2 <- window(data_ts, start = c(2017, 1), end = c(2017, 6))

# Train both model arima and ets
fit1 <- auto.arima(smpl1, seasonal = TRUE)
fit2 <- ets(smpl1)

# Check residuals for each model
checkresiduals(fit1)
checkresiduals(fit2)

# Produce forecasts for each model
fc1 <- forecast(fit1, h = 12)
fc2 <- forecast(fit2, h = 12)

# Display accuracy of the models
print("Accuracy calculation for ARiMA model")
print(accuracy(fc1, data_ts))
print("Accuracy calculation for ETS model")
print(accuracy(fc2, data_ts))

# Plot models, forecast and real records
autoplot(fc1, series = "Forecast") + 
  autolayer(smpl1, series = "Data for Model", lwd = 1.1) + 
  autolayer(fitted(fc1), series = "Fitted", lwd = 1.1) +
  autolayer(smpl2, series = "Actual Data", lty = 1, lwd = 1.5)

autoplot(fc2, series = "Forecast") + 
  autolayer(smpl1, series = "Data for Model", lwd = 1.1) + 
  autolayer(fitted(fc1), series = "Fitted", lwd = 1.1) +
  autolayer(smpl2, series = "Actual Data", lty = 1, lwd = 1.5)

```

**Interpretation:**

Both model are able to predict the seasonality observed in the exploratory part. The similarities between observations as a function of the time lag between them, given by the ACF does not show a significant auto-correlation (values in-between the twodashed blue lines).

Finally, we can also see that the ARIMA model is better at predicting future values as its RMSE is lower on the test set.

## Conclusion

We have demonstrated that the PM2.5 levels in Chengdu from 2013 to mid-2017 are decreasing overall and over time. We have presented the seasonality of the pollution with high level in December and January. The best period with lower risk of exposure is during the months of June and August. This trend has been succesfully captured and replicated in a preliminary forecasting model.

Air pollution is among the problems faced by cities across the world. Despite extreme values, the data shows a promising trend for the city of Chengdu.

To go further, we know that weather condition has an effect on air pollution. It would be interesting to investigate the correlation between the PM2.5 levels and parameters such as temperature and wind speed.

\newpage

## Annexes

### Monthly Seasonality Table

```{r}
maindf_pro %>%
  group_by(Year, Month) %>%
  summarize(MonthMean = round(mean(Value), digits = 2),
            MonthMedian = round(median(Value), digits = 2),
            MonthStd = round(sd(Value), digits = 2),
            MonthMax = max(Value),
            MonthMin = min(Value))
```

### R Session Info

```{r}
sessionInfo()
```
```