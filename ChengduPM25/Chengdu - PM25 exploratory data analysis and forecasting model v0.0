---
title: "PM2.5 level in Chengdu - Exploratory Data Analysis"
author: "Pierre Baudin"
date: "March 17, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis

Cities accross the world are facing air pollution problems that are generated by human activity. Air pollution has been recognized to be a factor in the increase of respiratory diseases in urban population.

Increasingly, cities are developing programs to reduce the air pollution and decrease the health risk on the population.

In this explanatory analysis, we will look at the city of Chengdu and its PM2.5 pollution level. PM2.5 stands for Particule Matter and describes fine inhalable particles, with diameters that are generally 2.5 micrometers and smaller.

The data for this project is collected from the American embassy in Chengdu. (see: http://www.stateair.net/web/post/1/2.html). We are grateful for the U.S. Department of State to open access to the data. The website also warns that these data are not fully verified or validated.

The objective of this project is to explore the dataset, identify trends and finally propose a forecasting model.

## Data preparation

### Collection and combining

The historical data from the American embassy in Chengdu are available for download. For each year from 2013 to 2017, there is one comma separated value file (.csv). All of the files have been downloaded.

A preliminary check (not shown here) has revealed that the data formating in the csv file has been changed between 2014 and 2015. For this reason, the import and binding is done in two stage.

```{r import combine, message=FALSE, warning=FALSE}
# Import libraries
library(dplyr) # data manipulation and pipe operator
library(lubridate) # easy processing of time-based data

# Set the working directory which contains the yearly historical data
setwd("C:/Users/pierr/Desktop/ChengduPM25")

# Create a vector with the files names
FileNames <- list.files(pattern = ".csv")

# Initiate main dataframe for all years combined
maindf <- data.frame()

# Loop to import and bind the year 2013 and 2014
for (i in 1:2) {
  df <- read.csv(FileNames[i], skip = 2)
  maindf <- bind_rows(maindf, df)
}

# Convert date into POSIXct POSIXt format
maindf$Date..LST. <- ymd_hm(maindf$Date..LST.)

# Loop over data from 2015 to 2017
for (i in 3:5) {
  df <- read.csv(FileNames[i], skip = 3)
  df$Date..LST. <- mdy_hm(df$Date..LST.) # convertion to standard date format
  maindf <- bind_rows(maindf, df)
}

# Convert features format
maindf$Value <- as.numeric(maindf$Value)
ind <- c("Year", "Month", "Day", "Hour")
maindf[, ind] <- lapply(maindf[, ind], as.factor)

# Convert month into coresponding string factors
monthdf <- data.frame(Nbr = as.factor(c(1:12)),
                      Month_str = factor(c("Jan", "Feb", "Mar", "Apr",
                                               "May", "Jun", "Jul", "Aug",
                                               "Sep", "Oct", "Nov", "Dec"),
                                            levels = c("Jan", "Feb", "Mar", "Apr",
                                               "May", "Jun", "Jul", "Aug",
                                               "Sep", "Oct", "Nov", "Dec")))
maindf <- maindf %>%
  left_join(monthdf, by = c("Month" = "Nbr")) %>%
  mutate(Month = Month_str, Month_str = NULL)


# Display structure and first rows of the main dataframe
str(maindf)
head(maindf)
```

### Interpretation of the dataset

```{r}
summary(maindf)
```

We can observe that the dataset is only for Chengdu as a site and the PM2.5 as a parameter. Observations are logged on an hourly basis. Interestingly we note that the number of observations for the year 2017 is incomplete. For the year 2013 to 2016, the number of observations correspond exactly to the number of days in the year multiplied by 24 hours.

Regarding the value measured, we see that the minimum is -999.00 which has no meaning. There are also 2036 observations with QC.Name as "Missing".

```{r}
table(maindf[maindf$Value == -999, "QC.Name"])
```

We can now confirm that the value recorded for missing QC is -999.

We choose to replace these missing value using a linear interpolation method. From then on, we will ignore the QC.Name variable.

```{r}
maindf$Value <- ifelse(maindf$Value < 0, NA, maindf$Value)
maindf_pro <- maindf
maindf_pro$Value <- na.approx(maindf_pro$Value)
maindf_pro$QC.Name <- NULL
```

This is now the summary of our final dataset ready for exploratory data analysis.
```{r}
summary(maindf_pro)
```

For the period of 2013 to mid-2017, the PM2.5 levels in Chengdu have a mean of 79.84 ug/m3, a median of 65.00 ug/m3. Peaks are observed at a maximum of 688.00 ug/m3 and a minimum of 0.00 ug/m3. We note that these value are extreme and need to be taken with caution. Elements such a measuring equipment, location and calibration could influence such readings.

## Visualization and Trends

### By Year

In this section, we will explore the PM2.5 level on a yearly basis and answer the following question: overall, have the PM2.5 pollution levels decrease over time in Chengdu?

Note: the year 2017 being incomplete, it will be ignored in this part of the analysis to avoid misinterpretation.

```{r}
# load library for data vizualisation
library(ggplot2)

# Yearly pollution level boxplot
maindf_pro %>%
  filter(Year != 2017) %>%
  ggplot(aes(x = Year, y = Value, group = Year)) +
  geom_boxplot() +
  labs(title = "PM2.5 level from 2013 to 2016 in Chengdu",
         x = "", y = "PM2.5 value (ug/m3)") +
  theme_light()
```

```{r}
maindf_pro %>%
  filter(Year != 2017) %>%
  group_by(Year) %>%
  summarize(YearMean = round(mean(Value), digits = 2),
            YearMedian = median(Value),
            YearStd = round(sd(Value), digits = 2),
            YearMax = max(Value),
            YearMin = min(Value))
```

**Interpretation:**

We can see that over the year, the average level of PM2.5 in the air has decreased overall. It seems to stabilize in 2016. However, the standard deviation indicates that there are less extreme readings in 2016 which the maximum value recorded in that year confirms.

### Seasonality

In this section, we will look at the monthly data to investigate trends over the year.
The year 2017 although incomplete is included in this analysis to make use of the monthly data.

```{r}
# Initiate color palette
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

# Ploting
maindf_pro %>%
  ggplot(aes(x = Month, y = Value, group = interaction(Year, Month), fill = Year)) +
  geom_boxplot(alpha = 0.6,
               outlier.fill = "red", outlier.alpha = 0.6) +
  scale_fill_manual(values = cbPalette) +
  scale_y_continuous(breaks = seq(0, 700, 50)) +
  labs(title = "Monthly PM2.5 distribution grouped by year",
       x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.justification = c(1, 1), legend.position = c(1, 1))
```

The table with monthly summary is available in the annexes section.

### Chinese New Year and PM2.5 level

```{r}
CNY_date <- data.frame(Year = c(2013, 2015, 2016),
                       CNY_date = c(10, 19, 8))

maindf_pro %>%
  filter(Month == "Feb", Year == c(2013, 2015, 2016)) %>%
  group_by(Year, Day) %>%
  summarize(DayMax = max(Value)) %>%
  ggplot(aes(x = Day, y = DayMax, group = Year, fill = Year)) +
  geom_col(alpha = 0.6) +
  facet_grid(Year ~ .) +
  geom_vline(aes(xintercept = CNY_date), CNY_date,
             lwd = 1.5, lty = 2, color = "red") +
  scale_fill_manual(values = cbPalette) +
  labs(title = "Monthly PM2.5 distribution grouped by year",
       x = "", y = "PM2.5 value (ug/m3)") +
  theme_light() +
  theme(legend.position = "none")

```

## Forecasting model

In this section, we will use the historical data from 2013 to 2016 and train a model to predict the pollution level in the first six months of 2017.
The data from 2017 will be kept as a test set to evaluate the model accuracy.

Trying to predict the median each day

Need to process the data

## Annexes

### Monthly Seasonality Table

```{r}
maindf_pro %>%
  group_by(Year, Month) %>%
  summarize(MonthMean = round(mean(Value), digits = 2),
            MonthMedian = round(median(Value), digits = 2),
            MonthStd = round(sd(Value), digits = 2),
            MonthMax = max(Value),
            MonthMin = min(Value))
```